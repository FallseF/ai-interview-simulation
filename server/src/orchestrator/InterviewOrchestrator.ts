import WebSocket from "ws";
import type { Speaker, Target, InterviewMode, EndReason, PatternConfig, AIPersonaConfig, PersonaConfig } from "../types/roles.js";
import type { ClientMessage, ServerMessage, EvaluationResultMessage } from "../types/ws.js";
import { INTERVIEW_CONFIG, MOCK_MODE } from "../config.js";
import { OpenAIRealtimeConnection, type OpenAIConnectionCallbacks } from "../realtime/openaiWs.js";
import { MockOpenAIRealtimeConnection, type MockScenario } from "../realtime/mockOpenaiWs.js";
import { TurnManager } from "./TurnManager.js";
import { TranscriptStore } from "./TranscriptStore.js";
import { Evaluator } from "../evaluation/Evaluator.js";
import { FeedbackFormatter } from "../evaluation/FeedbackFormatter.js";
import { SessionStore } from "../db/index.js";
// Pattern-specific configurations
import { createPattern1StudentConfig } from "../prompts/patterns/pattern1.js";
import { createPattern2InterviewerConfig, createPattern2StudentConfig } from "../prompts/patterns/pattern2.js";
import { createPattern3InterviewerConfig } from "../prompts/patterns/pattern3.js";
// Persona-aware configurations
import { createInterviewerConfig } from "../prompts/interviewer.js";
import { createCandidateConfig } from "../prompts/candidate.js";
import { DEFAULT_INTERVIEWER_PERSONA, DEFAULT_CANDIDATE_PERSONA } from "../prompts/persona/index.js";

// æŽ¥ç¶šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åž‹ï¼ˆæœ¬ç‰©ã¨ãƒ¢ãƒƒã‚¯ã§å…±é€šï¼‰
type AIConnection = OpenAIRealtimeConnection | MockOpenAIRealtimeConnection;

export class InterviewOrchestrator {
  private clientSocket: WebSocket;
  private interviewerConnection: AIConnection | null = null;
  private candidateConnection: AIConnection | null = null;

  private turnManager: TurnManager;
  private transcriptStore: TranscriptStore;
  private sessionStore: SessionStore;

  private interviewerReady = false;
  private candidateReady = false;
  private pendingStart = false;

  private interviewEnded = false;
  private endReason: EndReason = null;

  private currentTranscriptBuffer = "";
  private interviewStartTime: Date | null = null;

  // ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š
  private patternConfig: PatternConfig;

  // ãƒšãƒ«ã‚½ãƒŠè¨­å®š
  private personaConfig?: PersonaConfig;

  // ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚·ãƒŠãƒªã‚ªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  private mockScenario?: MockScenario;
  private autoProceedTimer: NodeJS.Timeout | null = null;
  private readonly autoProceedDelayMs = 4000;

  constructor(
    clientSocket: WebSocket,
    patternConfig: PatternConfig,
    mode: InterviewMode = "step",
    personaConfig?: PersonaConfig,
    mockScenario?: MockScenario
  ) {
    this.clientSocket = clientSocket;
    this.patternConfig = patternConfig;
    this.personaConfig = personaConfig;
    this.turnManager = new TurnManager(mode);
    this.transcriptStore = new TranscriptStore();
    this.sessionStore = new SessionStore();
    this.mockScenario = mockScenario;

    this.setupClientHandlers();
    this.setupAIConnections();

    // Automatically start interview when AI connections are ready
    // startInterview() will set pendingStart=true if connections aren't ready yet
    this.startInterview();
  }

  private setupClientHandlers(): void {
    this.clientSocket.on("message", (message) => {
      try {
        const data = JSON.parse(message.toString()) as ClientMessage;
        this.handleClientMessage(data);
      } catch (error) {
        console.error("[Orchestrator] Failed to parse client message:", error);
      }
    });

    this.clientSocket.on("close", () => {
      console.log("[Orchestrator] Client disconnected");
      this.cleanup();
    });

    this.clientSocket.on("error", (error) => {
      console.error("[Orchestrator] Client socket error:", error);
    });
  }

  /**
   * Get AI configurations based on the current pattern and persona settings
   */
  private getPatternConfigs(): { interviewerConfig: AIPersonaConfig | null; candidateConfig: AIPersonaConfig | null } {
    const { pattern, japaneseLevel } = this.patternConfig;
    const persona = this.personaConfig;
    console.log(`[Orchestrator] Getting configs for pattern: ${pattern}, japaneseLevel: ${japaneseLevel}, persona: ${persona ? "custom" : "default"}`);

    // ãƒšãƒ«ã‚½ãƒŠãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒšãƒ«ã‚½ãƒŠãƒ™ãƒ¼ã‚¹ã®è¨­å®šã‚’ä½¿ç”¨
    if (persona) {
      const interviewerPersona = persona.interviewer || DEFAULT_INTERVIEWER_PERSONA;
      const candidatePersona = persona.candidate || {
        ...DEFAULT_CANDIDATE_PERSONA,
        japaneseLevel: japaneseLevel || "N4",
      };

      // å€™è£œè€…ã®æ—¥æœ¬èªžãƒ¬ãƒ™ãƒ«ã‚’ãƒšãƒ«ã‚½ãƒŠè¨­å®šã‹ã‚‰ä¸Šæ›¸ã
      if (japaneseLevel && candidatePersona.japaneseLevel !== japaneseLevel) {
        candidatePersona.japaneseLevel = japaneseLevel;
      }

      console.log(`[Orchestrator] Using persona - Interviewer: ${interviewerPersona.personality}, ${interviewerPersona.dialect}`);
      console.log(`[Orchestrator] Using persona - Candidate: ${candidatePersona.japaneseLevel}`);

      switch (pattern) {
        case "pattern1":
          // å–¶æ¥­(human) vs å­¦ç”Ÿ(AI) - å€™è£œè€…ã®ã¿ãƒšãƒ«ã‚½ãƒŠä½¿ç”¨
          return {
            interviewerConfig: null,
            candidateConfig: createCandidateConfig(undefined, candidatePersona),
          };
        case "pattern2":
          // å–¶æ¥­(human) vs å­¦ç”Ÿ(AI) vs é¢æŽ¥å®˜(AI) - ä¸¡æ–¹ãƒšãƒ«ã‚½ãƒŠä½¿ç”¨
          return {
            interviewerConfig: createInterviewerConfig(undefined, interviewerPersona),
            candidateConfig: createCandidateConfig(undefined, candidatePersona),
          };
        case "pattern3":
          // å–¶æ¥­(human) vs é¢æŽ¥å®˜(AI) - é¢æŽ¥å®˜ã®ã¿ãƒšãƒ«ã‚½ãƒŠä½¿ç”¨
          return {
            interviewerConfig: createInterviewerConfig(undefined, interviewerPersona),
            candidateConfig: null,
          };
        default:
          return {
            interviewerConfig: createInterviewerConfig(undefined, interviewerPersona),
            candidateConfig: createCandidateConfig(undefined, candidatePersona),
          };
      }
    }

    // ãƒšãƒ«ã‚½ãƒŠãªã—ã®å ´åˆã¯å¾“æ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’ä½¿ç”¨
    switch (pattern) {
      case "pattern1":
        // å–¶æ¥­(human) vs å­¦ç”Ÿ(AI) - å‡ºå¸­ç¢ºèªãƒ»è‡ªå·±ç´¹ä»‹ç·´ç¿’
        return {
          interviewerConfig: null,
          candidateConfig: createPattern1StudentConfig({ japaneseLevel }),
        };
      case "pattern2":
        // å–¶æ¥­(human) vs å­¦ç”Ÿ(AI) vs é¢æŽ¥å®˜(AI) - é¢æŽ¥æœ¬ç•ª
        const candidateConfig = createPattern2StudentConfig({ japaneseLevel });
        console.log(`[Orchestrator] Candidate instructions preview (first 500 chars):`);
        console.log(candidateConfig.instructions.substring(0, 500));
        return {
          interviewerConfig: createPattern2InterviewerConfig(),
          candidateConfig,
        };
      case "pattern3":
        // å–¶æ¥­(human) vs é¢æŽ¥å®˜(AI) - å­¦ç”Ÿé€€å¸­å¾Œã®ãƒ’ã‚¢ãƒªãƒ³ã‚°
        return {
          interviewerConfig: createPattern3InterviewerConfig(),
          candidateConfig: null,
        };
      default:
        // Fallback to pattern2
        return {
          interviewerConfig: createPattern2InterviewerConfig(),
          candidateConfig: createPattern2StudentConfig({ japaneseLevel }),
        };
    }
  }

  private setupAIConnections(): void {
    const { interviewerConfig, candidateConfig } = this.getPatternConfigs();
    const { participants } = this.patternConfig;

    // ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ã¦å¿…è¦ãªæŽ¥ç¶šã‚’åˆ¤å®š
    const needsInterviewer = participants.includes("interviewer");
    const needsCandidate = participants.includes("candidate");

    console.log(`[Orchestrator] Pattern: ${this.patternConfig.pattern}, Participants: ${participants.join(", ")}`);

    // é¢æŽ¥å®˜æŽ¥ç¶šãŒä¸è¦ãªå ´åˆã¯å³åº§ã«readyæ‰±ã„
    if (!needsInterviewer) {
      this.interviewerReady = true;
    }
    // å€™è£œè€…æŽ¥ç¶šãŒä¸è¦ãªå ´åˆã¯å³åº§ã«readyæ‰±ã„
    if (!needsCandidate) {
      this.candidateReady = true;
    }

    // é¢æŽ¥å®˜ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    const interviewerCallbacks: OpenAIConnectionCallbacks = {
      onSessionReady: () => {
        this.interviewerReady = true;
        console.log("[Orchestrator] Interviewer session ready");
        this.checkAndStartInterview();
      },
      onAudioDelta: (audio) => this.handleAudioDelta("interviewer", audio),
      onAudioDone: () => this.handleAudioDone("interviewer"),
      onTranscriptDelta: (delta) => this.handleTranscriptDelta("interviewer", delta),
      onTranscriptDone: (text) => this.handleTranscriptDone("interviewer", text),
      onInputTranscriptDone: (text) => this.handleHumanTranscript(text),
      onResponseDone: (status, error) => this.handleResponseDone("interviewer", status, error),
      onError: (error) => this.handleError(error),
      onClose: () => this.handleConnectionClose("interviewer"),
    };

    // å€™è£œè€…ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    const candidateCallbacks: OpenAIConnectionCallbacks = {
      onSessionReady: () => {
        this.candidateReady = true;
        console.log("[Orchestrator] Candidate session ready");
        this.checkAndStartInterview();
      },
      onAudioDelta: (audio) => this.handleAudioDelta("candidate", audio),
      onAudioDone: () => this.handleAudioDone("candidate"),
      onTranscriptDelta: (delta) => this.handleTranscriptDelta("candidate", delta),
      onTranscriptDone: (text) => this.handleTranscriptDone("candidate", text),
      onInputTranscriptDone: (text) => this.handleHumanTranscript(text),
      onResponseDone: (status, error) => this.handleResponseDone("candidate", status, error),
      onError: (error) => this.handleError(error),
      onClose: () => this.handleConnectionClose("candidate"),
    };

    if (MOCK_MODE) {
      // ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: æœ¬ç‰©ã®APIã«ç¹‹ãŒãªã„
      console.log("[Orchestrator] ðŸ§ª Using mock connections");

      if (needsInterviewer && interviewerConfig) {
        this.interviewerConnection = new MockOpenAIRealtimeConnection(
          "Interviewer",
          interviewerConfig,
          interviewerCallbacks,
          this.mockScenario
        );
        this.interviewerConnection.connect();
      }

      if (needsCandidate && candidateConfig) {
        this.candidateConnection = new MockOpenAIRealtimeConnection(
          "Candidate",
          candidateConfig,
          candidateCallbacks,
          this.mockScenario
        );
        this.candidateConnection.connect();
      }
    } else {
      // æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: æœ¬ç‰©ã®OpenAI APIã«æŽ¥ç¶š
      if (needsInterviewer && interviewerConfig) {
        this.interviewerConnection = new OpenAIRealtimeConnection(
          "Interviewer",
          interviewerConfig,
          interviewerCallbacks
        );
        this.interviewerConnection.connect();
      }

      if (needsCandidate && candidateConfig) {
        this.candidateConnection = new OpenAIRealtimeConnection(
          "Candidate",
          candidateConfig,
          candidateCallbacks
        );
        this.candidateConnection.connect();
      }
    }
  }

  private handleClientMessage(data: ClientMessage): void {
    console.log("[Orchestrator] Client message:", data.type);

    switch (data.type) {
      // New protocol
      case "start_session":
        this.turnManager.setMode(data.mode);
        this.startInterview();
        break;

      case "set_mode":
        this.turnManager.setMode(data.mode);
        break;

      case "next_turn":
        this.handleNextTurn();
        break;

      case "human_text":
        this.handleHumanText(data.target, data.text);
        break;

      case "human_audio_chunk":
        this.handleHumanAudioChunk(data.target, data.audioBase64);
        break;

      case "human_audio_commit":
        this.handleHumanAudioCommit(data.target);
        break;

      case "end_session":
        this.endInterview("normal");
        break;

      // Legacy protocol support
      case "start_interview":
        this.startInterview();
        break;

      case "audio":
        // Legacy: send to both AIs
        this.handleHumanAudioChunk("both", data.data);
        break;

      case "audio_playback_done":
        this.handleAudioPlaybackDone();
        break;

      case "proceed_to_next":
        this.handleProceedToNext();
        break;

      case "user_will_speak":
        this.clearAutoProceedTimer();
        this.turnManager.onHumanSpeakStart();
        this.sendTurnState();
        // Legacy phase change
        this.sendLegacyPhaseChange("user_speaking", "è»¢è·æ”¯æ´");
        break;

      case "user_done_speaking":
        this.handleUserDoneSpeaking();
        break;
    }
  }

  private startInterview(): void {
    if (this.interviewerReady && this.candidateReady) {
      console.log(`[Orchestrator] Sessions ready, starting interview (pattern: ${this.patternConfig.pattern})`);
      this.sendToClient({
        type: "session_ready",
        pattern: this.patternConfig.pattern,
        japaneseLevel: this.patternConfig.japaneseLevel,
        participants: this.patternConfig.participants,
      });
      this.sendToClient({ type: "sessions_ready" }); // Legacy

      if (!this.interviewStartTime) {
        this.interviewStartTime = new Date();
        // DBã«ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚’è¨˜éŒ²
        this.sessionStore.startSession(
          this.patternConfig.pattern,
          this.turnManager.getMode(),
          this.patternConfig.japaneseLevel,
          this.personaConfig
        );
      }

      const initialSpeaker = this.patternConfig.pattern === "pattern1" ? "candidate" : "interviewer";
      this.turnManager.start(initialSpeaker);
      this.sendTurnState();

      // ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸé–‹å§‹å‡¦ç†
      const { pattern } = this.patternConfig;

      if (pattern === "pattern1") {
        // pattern1: å€™è£œè€…ï¼ˆå¤–å›½äººå­¦ç”Ÿï¼‰ã®ã¿ - å€™è£œè€…ã‹ã‚‰é–‹å§‹
        this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
        this.candidateConnection?.requestResponse();
      } else if (pattern === "pattern2") {
        // pattern2: ä¸¡æ–¹ - é¢æŽ¥å®˜ã‹ã‚‰é–‹å§‹ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
        this.interviewerConnection?.requestResponse();
      } else if (pattern === "pattern3") {
        // pattern3: é¢æŽ¥å®˜ã®ã¿ - é¢æŽ¥å®˜ã‹ã‚‰é–‹å§‹
        this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
        this.interviewerConnection?.requestResponse();
      }
    } else {
      console.log("[Orchestrator] Waiting for sessions to be ready...");
      this.pendingStart = true;
      this.sendToClient({ type: "waiting_for_sessions" });
    }
  }

  private checkAndStartInterview(): void {
    if (this.pendingStart && this.interviewerReady && this.candidateReady) {
      this.pendingStart = false;
      this.startInterview();
    }
  }

  private handleNextTurn(): void {
    if (this.interviewEnded) return;

    // å¾…æ©Ÿä¸­ã§ãªã‘ã‚Œã°ç„¡è¦–ï¼ˆå¤šé‡é€ä¿¡é˜²æ­¢ï¼‰
    const stateBefore = this.turnManager.getState();
    if (!stateBefore.waitingForNext) return;

    this.turnManager.onNextTurn();
    const state = this.turnManager.getState();
    this.sendTurnState();

    if (state.currentSpeaker === "interviewer" && this.interviewerConnection) {
      this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
      this.interviewerConnection.requestResponse();
    } else if (state.currentSpeaker === "candidate" && this.candidateConnection) {
      this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
      this.candidateConnection.requestResponse();
    }
  }

  private handleHumanText(target: Target, text: string): void {
    this.clearAutoProceedTimer();
    this.turnManager.onHumanSpeakStart();
    this.sendTurnState();

    const contextMessage = `[è»¢è·æ”¯æ´ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ]: ${text}`;

    // Add to transcript
    this.transcriptStore.commit("human", text);
    this.sendToClient({
      type: "transcript_done",
      speaker: "human",
      text,
    });

    // Send to target AI(s)
    if (target === "interviewer" || target === "both") {
      this.interviewerConnection?.addTextMessage(contextMessage);
    }
    if (target === "candidate" || target === "both") {
      this.candidateConnection?.addTextMessage(contextMessage);
    }

    // Proceed after human input
    this.turnManager.onHumanSpeakDone();
    this.sendTurnState();

    // Auto trigger response after human text based on pattern
    if (this.turnManager.getMode() === "auto") {
      const { pattern } = this.patternConfig;
      if (pattern === "pattern1" && this.candidateConnection) {
        this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
        this.candidateConnection.requestResponse();
      } else if (this.interviewerConnection) {
        this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
        this.interviewerConnection.requestResponse();
      }
    }
  }

  private handleHumanAudioChunk(target: Target, audioBase64: string): void {
    this.clearAutoProceedTimer();
    if (target === "interviewer" || target === "both") {
      this.interviewerConnection?.appendAudio(audioBase64);
    }
    if (target === "candidate" || target === "both") {
      this.candidateConnection?.appendAudio(audioBase64);
    }
  }

  private handleHumanAudioCommit(target: Target): void {
    this.clearAutoProceedTimer();
    if (target === "interviewer" || target === "both") {
      this.interviewerConnection?.commitAudio();
    }
    if (target === "candidate" || target === "both") {
      this.candidateConnection?.commitAudio();
    }

    this.turnManager.onHumanSpeakDone();
    this.sendTurnState();

    // autoãƒ¢ãƒ¼ãƒ‰æ™‚ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸå¿œç­”è¦æ±‚
    if (this.turnManager.getMode() === "auto") {
      const { pattern } = this.patternConfig;
      if (pattern === "pattern1" && this.candidateConnection) {
        this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
        this.candidateConnection.requestResponse();
      } else if (this.interviewerConnection) {
        this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
        this.interviewerConnection.requestResponse();
      }
    }
  }

  private handleAudioDelta(speaker: Speaker, audioBase64: string): void {
    // Send audio to client (only new format, no legacy duplicate)
    this.sendToClient({
      type: "audio_delta",
      speaker,
      audioBase64,
    });
  }

  private handleAudioDone(speaker: Speaker): void {
    console.log(`[Orchestrator] Audio done for ${speaker}`);

    this.sendToClient({
      type: "audio_done",
      speaker,
    });
  }

  private handleTranscriptDelta(speaker: Speaker, delta: string): void {
    this.transcriptStore.addDelta(speaker, delta);

    this.sendToClient({
      type: "transcript_delta",
      speaker,
      textDelta: delta,
    });
  }

  private handleTranscriptDone(speaker: Speaker, fullText: string): void {
    this.transcriptStore.commit(speaker, fullText);
    // DBã«ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿å­˜
    this.sessionStore.addTranscript(speaker, fullText);

    this.sendToClient({
      type: "transcript_done",
      speaker,
      text: fullText,
    });

    // Share context with other AI
    this.shareContextWithOtherAI(speaker, fullText);

    // Check for interview end markers
    this.checkForEndMarkers(fullText);
  }

  private handleHumanTranscript(text: string): void {
    this.clearAutoProceedTimer();
    this.transcriptStore.commit("human", text);
    // DBã«ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¿å­˜
    this.sessionStore.addTranscript("human", text);

    this.sendToClient({
      type: "transcript_done",
      speaker: "human",
      text,
    });
  }

  private handleResponseDone(speaker: Speaker, status: string, errorMessage?: string): void {
    console.log(`[Orchestrator] Response done for ${speaker}: ${status}`);

    if (status !== "completed" && errorMessage) {
      console.error(`[Orchestrator] Response error: ${errorMessage}`);
      this.sendToClient({
        type: "error",
        message: `${speaker} response failed: ${errorMessage}`,
      });
    }
    // Turn progression is handled in handleAudioPlaybackDone to prevent double triggers
  }

  private handleAudioPlaybackDone(): void {
    this.clearAutoProceedTimer();
    if (this.interviewEnded) {
      this.sendLegacyPhaseChange("ended", undefined, this.endReason || undefined);
      return;
    }

    const state = this.turnManager.getState();
    const isStepMode = this.turnManager.getMode() === "step";
    const { pattern } = this.patternConfig;

    if (state.phase === "interviewer" || state.currentSpeaker === "interviewer") {
      if (isStepMode) {
        // Step mode: wait for user to proceed
        this.turnManager.onAISpeakingDone("interviewer");
        this.sendTurnState();
        this.sendLegacyPhaseChange("user_choice");
      } else {
        // Auto mode: ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸæ¬¡ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼
        if (pattern === "pattern2" && this.candidateConnection) {
          // pattern2: å€™è£œè€…ãŒå¿œç­”
          this.turnManager.setSpeaker("candidate");
          this.sendTurnState();
          this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
          this.candidateConnection.requestResponse();
        } else {
          // pattern3 or no candidate: user choice
          this.turnManager.onAISpeakingDone("interviewer");
          this.sendTurnState();
          this.sendLegacyPhaseChange("user_choice");
        }
      }
    } else if (state.phase === "candidate" || state.currentSpeaker === "candidate") {
      if (isStepMode) {
        // Step mode: wait for user to proceed
        this.turnManager.onAISpeakingDone("candidate");
        this.sendTurnState();
        this.sendLegacyPhaseChange("user_choice");
      } else {
        // Auto mode: å€™è£œè€…ã®å¾Œã¯ä¸€æ—¦è£œè¶³ã®çŒ¶äºˆã‚’ä½œã‚‹
        this.turnManager.onAISpeakingDone("candidate");
        this.sendTurnState();
        this.sendLegacyPhaseChange("user_choice");
        this.scheduleAutoProceedAfterCandidate();
      }
    } else if (state.phase === "user_speaking" || state.currentSpeaker === "human") {
      if (isStepMode) {
        // Step mode: wait for user to proceed
        this.turnManager.onHumanSpeakDone();
        this.sendTurnState();
        this.sendLegacyPhaseChange("user_choice");
      } else {
        // Auto mode: ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸæ¬¡ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼
        if (pattern === "pattern1" && this.candidateConnection) {
          // pattern1: å€™è£œè€…ãŒå¿œç­”
          this.turnManager.setSpeaker("candidate");
          this.sendTurnState();
          this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
          this.candidateConnection.requestResponse();
        } else if (this.interviewerConnection) {
          // pattern2, pattern3: é¢æŽ¥å®˜ãŒå¿œç­”
          this.turnManager.setSpeaker("interviewer");
          this.sendTurnState();
          this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
          this.interviewerConnection.requestResponse();
        } else {
          this.turnManager.onHumanSpeakDone();
          this.sendTurnState();
          this.sendLegacyPhaseChange("user_choice");
        }
      }
    }
  }

  private handleProceedToNext(): void {
    if (this.interviewEnded) return;
    this.clearAutoProceedTimer();

    const { pattern } = this.patternConfig;

    // User chose to proceed without commenting
    // ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸæ¬¡ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’æ±ºå®š
    if (pattern === "pattern1" && this.candidateConnection) {
      // pattern1: å€™è£œè€…ã®ã¿
      this.turnManager.setSpeaker("candidate");
      this.sendTurnState();
      this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
      this.candidateConnection.requestResponse();
    } else if (this.interviewerConnection) {
      // pattern2, pattern3: é¢æŽ¥å®˜å„ªå…ˆ
      this.turnManager.setSpeaker("interviewer");
      this.sendTurnState();
      this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
      this.interviewerConnection.requestResponse();
    }
  }

  private handleUserDoneSpeaking(): void {
    this.clearAutoProceedTimer();
    const { pattern } = this.patternConfig;

    // Commit audio to connected AIs only
    this.interviewerConnection?.commitAudio();
    this.candidateConnection?.commitAudio();

    this.turnManager.onHumanSpeakDone();
    this.sendTurnState();

    // ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸæ¬¡ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼
    if (pattern === "pattern1" && this.candidateConnection) {
      // pattern1: å€™è£œè€…ãŒå¿œç­”
      this.sendLegacyPhaseChange("maria_speaking", "ã‚°ã‚¨ãƒ³ãƒ»ãƒŸãƒ³");
      this.candidateConnection.requestResponse();
    } else if (this.interviewerConnection) {
      // pattern2, pattern3: é¢æŽ¥å®˜ãŒå¿œç­”
      this.sendLegacyPhaseChange("interviewer", "ç”°ä¸­éƒ¨é•·");
      this.interviewerConnection.requestResponse();
    }
  }

  private shareContextWithOtherAI(speaker: Speaker, text: string): void {
    const label = speaker === "interviewer" ? "é¢æŽ¥å®˜ãŒè¨€ã„ã¾ã—ãŸ" : "æ±‚è·è€…ãŒè¨€ã„ã¾ã—ãŸ";
    const contextMessage = `[${label}]: ${text}`;

    if (speaker === "interviewer") {
      this.candidateConnection?.addTextMessage(contextMessage);
    } else if (speaker === "candidate") {
      this.interviewerConnection?.addTextMessage(contextMessage);
    }
  }

  private checkForEndMarkers(text: string): void {
    if (text.includes(INTERVIEW_CONFIG.END_MARKER)) {
      console.log("[Orchestrator] Interview end marker detected");
      this.endInterview("normal");
    } else if (text.includes(INTERVIEW_CONFIG.ABORT_MARKER)) {
      console.log("[Orchestrator] Interview abort marker detected");
      this.endInterview("aborted");
    }
  }

  private endInterview(reason: EndReason): void {
    this.interviewEnded = true;
    this.endReason = reason;
    this.clearAutoProceedTimer();
    this.turnManager.end();
    this.sendTurnState();

    // DBã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ã‚’è¨˜éŒ²
    this.sessionStore.endSession(reason);

    // è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡
    this.performEvaluation();
  }

  /**
   * é¢æŽ¥çµ‚äº†å¾Œã®è©•ä¾¡ã‚’å®Ÿè¡Œ
   */
  private performEvaluation(): void {
    console.log("[Orchestrator] Starting evaluation...");

    try {
      const evaluator = new Evaluator(undefined, this.interviewStartTime || undefined);
      const transcripts = this.transcriptStore.getAll();
      const result = evaluator.evaluate(transcripts);

      // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§å‡ºåŠ›
      console.log("\n" + FeedbackFormatter.toText(result));

      // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«JSONå½¢å¼ã§é€ä¿¡
      const resultJson = FeedbackFormatter.toJSON(result) as EvaluationResultMessage;
      this.sendToClient({
        type: "evaluation_result",
        result: resultJson,
      });

      // DBã«è©•ä¾¡çµæžœã‚’ä¿å­˜
      this.sessionStore.saveEvaluation(resultJson);

      console.log("[Orchestrator] Evaluation completed and sent to client");
    } catch (error) {
      console.error("[Orchestrator] Evaluation error:", error);
      this.sendToClient({
        type: "error",
        message: `è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error}`,
      });
    }
  }

  private handleError(error: Error): void {
    console.error("[Orchestrator] Error:", error.message);
    this.sendToClient({
      type: "error",
      message: error.message,
    });
  }

  private handleConnectionClose(which: "interviewer" | "candidate"): void {
    console.log(`[Orchestrator] ${which} connection closed`);
    if (which === "interviewer") {
      this.interviewerReady = false;
    } else {
      this.candidateReady = false;
    }
  }

  private sendTurnState(): void {
    const state = this.turnManager.getState();

    this.sendToClient({
      type: "turn_state",
      currentSpeaker: state.currentSpeaker,
      waitingForNext: state.waitingForNext,
      phase: state.phase,
      mode: this.turnManager.getMode(),
    });
  }

  private sendLegacyPhaseChange(phase: string, speaker?: string, reason?: string): void {
    const message: ServerMessage = {
      type: "phase_change",
      phase,
    };
    if (speaker) message.speaker = speaker;
    if (reason) message.reason = reason;
    this.sendToClient(message);
  }

  private sendToClient(message: ServerMessage): void {
    if (this.clientSocket.readyState === WebSocket.OPEN) {
      this.clientSocket.send(JSON.stringify(message));
    }
  }

  private cleanup(): void {
    this.clearAutoProceedTimer();
    this.interviewerConnection?.close();
    this.candidateConnection?.close();
    this.interviewerConnection = null;
    this.candidateConnection = null;
  }

  private scheduleAutoProceedAfterCandidate(): void {
    this.clearAutoProceedTimer();
    this.autoProceedTimer = setTimeout(() => {
      this.autoProceedTimer = null;
      if (this.interviewEnded) return;
      const state = this.turnManager.getState();
      if (state.phase !== "user_choice") return;
      this.handleProceedToNext();
    }, this.autoProceedDelayMs);
  }

  private clearAutoProceedTimer(): void {
    if (this.autoProceedTimer) {
      clearTimeout(this.autoProceedTimer);
      this.autoProceedTimer = null;
    }
  }
}
